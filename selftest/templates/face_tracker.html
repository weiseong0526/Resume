<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Tracker - Age, Gender & Glasses Detection</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 0.9em;
        }

        .scanner-section {
            display: block;
            margin-bottom: 30px;
        }

        .video-container {
            position: relative;
            background: #000;
            border-radius: 15px;
            overflow: hidden;
            aspect-ratio: 4/3;
        }

        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        #trackingCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: 10;
            background: transparent;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-bottom: 20px;
        }

        .btn {
            padding: 12px 30px;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 600;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-primary:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .btn-secondary {
            background: #6c757d;
            color: white;
        }

        .btn-secondary:hover:not(:disabled) {
            background: #5a6268;
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .status {
            text-align: center;
            padding: 10px;
            margin: 15px 0;
            border-radius: 10px;
            font-weight: 500;
        }

        .status.active {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.inactive {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }

        .status-indicator.active {
            background: #28a745;
            box-shadow: 0 0 10px rgba(40, 167, 69, 0.5);
        }

        .status-indicator.inactive {
            background: #dc3545;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ‘¤ Face Tracker</h1>
        <p class="subtitle">Detect age, gender in real-time</p>
        <p class="subtitle">click the start camera and wait a moment to see the result</p>

        <div class="scanner-section">
            <div class="video-container">
                <video id="video" autoplay playsinline muted></video>
                <canvas id="trackingCanvas"></canvas>
            </div>
            
            <div id="status" class="status inactive" style="margin-top: 20px;">
                <span class="status-indicator inactive"></span>
                <span id="statusText">Camera Stopped</span>
            </div>
        </div>

        <div class="controls">
            <button class="btn btn-primary" id="startBtn" onclick="startScanning()">Start Camera</button>
            <button class="btn btn-secondary" id="stopBtn" onclick="stopScanning()" disabled>Stop Camera</button>
        </div>
    </div>

    <!-- Face-API.js for face detection and analysis -->
    <!-- Try multiple CDN sources for better reliability -->
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js" 
            onerror="loadFaceAPIFallback()"></script>
    <script>
        function loadFaceAPIFallback() {
            console.log('Primary CDN failed, trying fallback...');
            const script = document.createElement('script');
            script.src = 'https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js';
            script.onerror = function() {
                console.error('All Face-API.js CDN sources failed');
                document.body.innerHTML += `
                    <div style="position: fixed; top: 0; left: 0; right: 0; background: #f8d7da; color: #721c24; padding: 20px; text-align: center; z-index: 10000;">
                        <strong>Error:</strong> Failed to load Face-API.js library. Please check your internet connection and refresh the page.
                    </div>
                `;
            };
            document.head.appendChild(script);
        }
        
        // Check if faceapi is loaded
        window.addEventListener('load', function() {
            setTimeout(function() {
                if (typeof faceapi === 'undefined') {
                    console.error('Face-API.js not loaded');
                    loadFaceAPIFallback();
                }
            }, 2000);
        });
    </script>

    <script>
        let video = null;
        let scanning = false;
        let stream = null;
        let trackingCanvas = null;
        let trackingCtx = null;
        let modelsLoaded = false;
        let detectedFaces = [];
        let frameCount = 0;
        const DETECTION_INTERVAL = 2; // Process every 2nd frame for speed (skip frames)

        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', () => {
            video = document.getElementById('video');
            trackingCanvas = document.getElementById('trackingCanvas');
            if (trackingCanvas) {
                trackingCtx = trackingCanvas.getContext('2d');
            }
            
            // Wait for Face-API.js library to load, then load models
            function waitForFaceAPI() {
                if (typeof faceapi !== 'undefined' && faceapi.nets) {
                    console.log('âœ“ Face-API.js library loaded');
                    loadModels();
                } else {
                    console.log('Waiting for Face-API.js to load...');
                    setTimeout(waitForFaceAPI, 100);
                }
            }
            
            // Start waiting after a short delay to ensure script has time to load
            setTimeout(waitForFaceAPI, 500);
        });

        async function loadModels() {
            try {
                updateStatus(false, 'Loading AI models...');
                console.log('Starting model loading...');
                
                // Try multiple CDN sources for better reliability
                const MODEL_URLS = [
                    'https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights',
                    'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights',
                    'https://unpkg.com/face-api.js@0.22.2/weights'
                ];
                
                let modelUrl = MODEL_URLS[0];
                let modelsLoadedSuccessfully = false;
                
                // Try each CDN until one works
                for (const url of MODEL_URLS) {
                    try {
                        console.log(`Trying to load models from: ${url}`);
                        modelUrl = url;
                        
                        // Load models with timeout
                        await Promise.race([
                            Promise.all([
                                faceapi.nets.tinyFaceDetector.loadFromUri(modelUrl),
                                faceapi.nets.faceLandmark68Net.loadFromUri(modelUrl),
                                faceapi.nets.faceRecognitionNet.loadFromUri(modelUrl),
                                faceapi.nets.ageGenderNet.loadFromUri(modelUrl)
                            ]),
                            new Promise((_, reject) => 
                                setTimeout(() => reject(new Error('Model loading timeout')), 30000)
                            )
                        ]);
                        
                        modelsLoadedSuccessfully = true;
                        console.log(`âœ“ Models loaded successfully from: ${url}`);
                        break;
                    } catch (err) {
                        console.warn(`Failed to load from ${url}:`, err);
                        // Try next URL
                        continue;
                    }
                }
                
                if (!modelsLoadedSuccessfully) {
                    throw new Error('All CDN sources failed. Please check your internet connection.');
                }
                
                modelsLoaded = true;
                console.log('âœ“ All Face-API models loaded successfully');
                updateStatus(false, 'Ready - Click "Start Camera" to begin');
            } catch (e) {
                console.error('Error loading models:', e);
                updateStatus(false, 'AI models failed to load: ' + e.message);
                
                // Show helpful error message
                const errorMsg = `
                    <div style="background: #f8d7da; color: #721c24; padding: 15px; border-radius: 10px; margin: 20px 0;">
                        <strong>Model Loading Error:</strong><br>
                        ${e.message}<br><br>
                        <strong>Possible solutions:</strong><br>
                        1. Check your internet connection<br>
                        2. Try refreshing the page<br>
                        3. Check browser console for details
                    </div>
                `;
                document.querySelector('.container').insertAdjacentHTML('beforeend', errorMsg);
            }
        }

        async function startScanning() {
            try {
                if (!modelsLoaded) {
                    alert('AI models not ready. Please wait...');
                    return;
                }

                updateStatus(true, 'Starting camera...');

                // Get user media - use lower resolution for faster processing
                stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'user', // Front camera for face tracking
                        width: { ideal: 640, max: 640 }, // Lower resolution = faster processing
                        height: { ideal: 480, max: 480 },
                        frameRate: { ideal: 30, max: 30 } // Limit frame rate for performance
                    }
                });

                video.srcObject = stream;
                video.setAttribute('autoplay', '');
                video.setAttribute('playsinline', '');
                video.setAttribute('muted', '');

                await video.play();

                // Set canvas size to match video
                if (trackingCanvas && video && video.videoWidth > 0) {
                    trackingCanvas.width = video.videoWidth;
                    trackingCanvas.height = video.videoHeight;
                    console.log('âœ“ Tracking canvas sized:', trackingCanvas.width, 'x', trackingCanvas.height);
                } else {
                    video.addEventListener('loadedmetadata', () => {
                        if (trackingCanvas && video && video.videoWidth > 0) {
                            trackingCanvas.width = video.videoWidth;
                            trackingCanvas.height = video.videoHeight;
                            console.log('âœ“ Tracking canvas sized (after metadata):', trackingCanvas.width, 'x', trackingCanvas.height);
                        }
                    }, { once: true });
                }

                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                
                scanning = true;
                updateStatus(true, 'Tracking faces...');
                
                // Start face detection
                setTimeout(() => {
                    detectFaces();
                }, 500);
                
            } catch (err) {
                console.error('Error accessing camera:', err);
                updateStatus(false, 'Camera Error: ' + err.message);
                alert('Error accessing camera: ' + err.message);
            }
        }

        async function detectFaces() {
            if (!scanning || !modelsLoaded) return;

            frameCount++;
            
            // Skip frames for faster performance - only process every Nth frame
            if (frameCount % DETECTION_INTERVAL !== 0) {
                // Still draw previous detections for smooth tracking
                if (detectedFaces.length > 0) {
                    drawFaces(detectedFaces);
                }
                if (scanning) {
                    requestAnimationFrame(detectFaces);
                }
                return;
            }

            try {
                // Use faster detection options for better performance
                const detectionOptions = new faceapi.TinyFaceDetectorOptions({
                    inputSize: 320, // Smaller input size = faster (was default 416)
                    scoreThreshold: 0.5 // Lower threshold = faster detection
                });

                // Detect ALL faces with age and gender (supports multiple people)
                const detections = await faceapi
                    .detectAllFaces(video, detectionOptions)
                    .withFaceLandmarks()
                    .withAgeAndGender();
                
                console.log(`Detected ${detections.length} face(s)`);

                // Update detected faces
                detectedFaces = detections;

                // Draw faces on canvas
                drawFaces(detections);

                // Continue detection - use requestAnimationFrame for smoother performance
                if (scanning) {
                    requestAnimationFrame(detectFaces);
                }
            } catch (err) {
                console.error('Face detection error:', err);
                if (scanning) {
                    requestAnimationFrame(detectFaces);
                }
            }
        }

        function drawFaces(detections) {
            if (!trackingCtx || !trackingCanvas) return;

            // Clear canvas
            trackingCtx.clearRect(0, 0, trackingCanvas.width, trackingCanvas.height);

            if (detections.length === 0) return;

            // Scale to match canvas size
            const resizedDetections = faceapi.resizeResults(detections, {
                width: trackingCanvas.width,
                height: trackingCanvas.height
            });

            // Draw each detected face with different colors for better distinction
            const colors = ['#00ff00', '#00ffff', '#ffff00', '#ff00ff', '#ff8800', '#00ff88'];
            
            resizedDetections.forEach((detection, index) => {
                const box = detection.detection.box;
                const age = Math.round(detection.age);
                const gender = detection.gender;
                const genderProbability = detection.genderProbability;
                
                // Use different colors for each face to distinguish multiple people
                const faceColor = colors[index % colors.length];
                
                // Draw face box - make it more visible with unique color
                trackingCtx.strokeStyle = faceColor;
                trackingCtx.lineWidth = 4;
                trackingCtx.shadowColor = faceColor;
                trackingCtx.shadowBlur = 10;
                trackingCtx.strokeRect(box.x, box.y, box.width, box.height);
                
                // Draw corner markers for each face
                const cornerSize = 15;
                trackingCtx.fillStyle = faceColor;
                trackingCtx.shadowBlur = 5;
                // Top-left
                trackingCtx.fillRect(box.x - 2, box.y - 2, cornerSize, 4);
                trackingCtx.fillRect(box.x - 2, box.y - 2, 4, cornerSize);
                // Top-right
                trackingCtx.fillRect(box.x + box.width - cornerSize + 2, box.y - 2, cornerSize, 4);
                trackingCtx.fillRect(box.x + box.width - 2, box.y - 2, 4, cornerSize);
                // Bottom-left
                trackingCtx.fillRect(box.x - 2, box.y + box.height - 2, cornerSize, 4);
                trackingCtx.fillRect(box.x - 2, box.y + box.height - cornerSize + 2, 4, cornerSize);
                // Bottom-right
                trackingCtx.fillRect(box.x + box.width - cornerSize + 2, box.y + box.height - 2, cornerSize, 4);
                trackingCtx.fillRect(box.x + box.width - 2, box.y + box.height - cornerSize + 2, 4, cornerSize);

                // Determine age group
                const ageGroup = getAgeGroup(age);

                // Draw info above face with face number
                const textY = box.y - 10;
                const genderText = gender.charAt(0).toUpperCase() + gender.slice(1); // Capitalize first letter
                const infoText = [
                    `Face ${index + 1}`,
                    `Gender: ${genderText}`,
                    `Age: ${Math.round(age)} (${ageGroup})`
                ];

                // Draw background for text
                trackingCtx.fillStyle = 'rgba(0, 0, 0, 0.8)';
                const textHeight = 20 * infoText.length + 10;
                trackingCtx.fillRect(box.x, textY - textHeight, box.width, textHeight);

                // Draw text with face-specific color
                trackingCtx.fillStyle = faceColor;
                trackingCtx.font = 'bold 14px Arial';
                trackingCtx.textAlign = 'left';
                trackingCtx.shadowBlur = 5;
                infoText.forEach((text, i) => {
                    trackingCtx.fillText(text, box.x + 5, textY - textHeight + 20 + (i * 20));
                });
                
                // Reset shadow
                trackingCtx.shadowBlur = 0;
            });
        }


        function getAgeGroup(age) {
            if (age < 13) return 'Kid';
            if (age < 18) return 'Teen';
            if (age < 30) return 'Young';
            if (age < 50) return 'Adult';
            if (age < 65) return 'Middle-aged';
            return 'Old';
        }


        function stopScanning() {
            scanning = false;
            
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }

            if (video) {
                video.srcObject = null;
                video.pause();
            }

            // Clear canvas
            if (trackingCtx && trackingCanvas) {
                trackingCtx.clearRect(0, 0, trackingCanvas.width, trackingCanvas.height);
            }

            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            updateStatus(false, 'Camera Stopped');
            detectedFaces = [];
        }

        function updateStatus(active, text) {
            const status = document.getElementById('status');
            const statusText = document.getElementById('statusText');
            
            if (active) {
                status.className = 'status active';
                status.querySelector('.status-indicator').className = 'status-indicator active';
            } else {
                status.className = 'status inactive';
                status.querySelector('.status-indicator').className = 'status-indicator inactive';
            }
            
            statusText.textContent = text;
        }
    </script>
</body>
</html>

